import os
import akshare as ak
import pandas as pd
import backtrader as bt
from abc import ABC, abstractmethod

class BaseDataLoader(ABC):
    def __init__(self, cache_path=None):
        self.cache_path = cache_path

    def load_data(self, **kwargs):
        print(f"ğŸ“ åŠ è½½å‚æ•°: {kwargs}")
        
        cache_file = self.cache_path or self._make_cache_file(**kwargs)
        print(f"ğŸ“‚ ç¼“å­˜è·¯å¾„: {cache_file}")
        
        if os.path.exists(cache_file):
            # ä»ç¼“å­˜è¯»å–æ—¶ï¼Œdatetimeå·²ç»æ˜¯ç´¢å¼•ï¼Œç›´æ¥è¿”å›
            data = pd.read_csv(cache_file, index_col='datetime', parse_dates=['datetime'])
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {data.shape}")
            return data
        else:
            # ä»akshareè·å–æ—¶ï¼Œéœ€è¦å¤„ç†åˆ—åå’Œç´¢å¼•
            print(" ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹ä»æ•°æ®æºè·å–æ•°æ®...")
            data = self.fetch_data(**kwargs)
            data.to_csv(cache_file)
            print(f"âœ… æ•°æ®è·å–å¹¶ä¿å­˜æˆåŠŸï¼Œå½¢çŠ¶: {data.shape}")
            return data

    @abstractmethod
    def fetch_data(self, **kwargs):
        """å­ç±»å®ç°ï¼šä»å…·ä½“æ•°æ®æºæ‹‰å–åŸå§‹æ•°æ®å¹¶åšé¢„å¤„ç†ï¼Œè¿”å›DataFrame"""
        pass

    def _make_cache_file(self, **kwargs):
        # å°è¯•ç”¨ fund_code æˆ– symbol, start_date, end_date ç”Ÿæˆæ–‡ä»¶å
        symbol = kwargs.get('symbol')
        start_date = kwargs.get('start_date', 'start')
        end_date = kwargs.get('end_date', 'end')
        
        # ç¡®ä¿dataç›®å½•å­˜åœ¨
        data_dir = "data"
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        filename = f"data_cache_{self.__class__.__name__}_{symbol}_{start_date}_{end_date}.csv"
        return os.path.join(data_dir, filename)

    def transfer_to_datafeed(self, data, required_cols=None):
        """
        å°† pandas DataFrame è½¬æ¢ä¸º Backtrader å¯ç”¨çš„æ•°æ®æºã€‚
        
        :param data: pandas DataFrameï¼Œç´¢å¼•ä¸º datetime
        :param required_columns: éœ€è¦çš„å­—æ®µåˆ—è¡¨ï¼ˆå¦‚ ["open", "high", "rsi"]ï¼‰ï¼Œ
                                å¦‚æœä¸º None æˆ–åªåŒ…å«æ ‡å‡† OHLCVï¼Œåˆ™ä½¿ç”¨æ ‡å‡† PandasDataã€‚
        :return: bt.feeds.PandasData æˆ–å…¶å­ç±»çš„å®ä¾‹
        """
        # 0. ç¡®ä¿è¾“å…¥æ˜¯å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹ DataFrame
        data=data.copy()
        # 1. å®šä¹‰ backtrader é»˜è®¤è¯†åˆ«çš„æ ‡å‡†åˆ—
        standard_cols = ["open", "high", "low", "close", "volume"]
        # 2. éªŒè¯æ ‡å‡†åˆ—çš„stræ˜¯å¦åœ¨æ•°æ®çš„ç´¢å¼•ä¸­
        data_list=data.columns.tolist()
        for col in standard_cols:
            if col not in data_list:
                raise ValueError(f"æ•°æ®ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—: {col}")
        # 3. å¦‚æœä¸ä¼ å…¥ required_columnsåˆ—è¡¨ï¼Œåˆ™å°†dataä¸­çš„æ ‡å‡†åˆ—èµ‹å€¼ç»™data_feed
        if required_cols is None:
            # --- æƒ…å†µä¸€ï¼šæ²¡æœ‰é™„åŠ åˆ—æˆ–é™„åŠ åˆ—ä¸ºç©º ---
            data = data[standard_cols]
            data_feed=bt.feeds.PandasData(dataname=data)
        else:
            # --- æƒ…å†µäºŒï¼šæœ‰é™„åŠ åˆ— ---
            # å°†required_colsä¸­ä¸åœ¨standard_colsä¸­çš„åˆ—èµ‹å€¼ç»™custom_colsï¼Œå»ºç«‹è‡ªå®šä¹‰PandasDataç±»ï¼ŒæŠŠcustom_colsèµ‹å€¼ç»™linesï¼ŒæŠŠcustom_colsèµ‹å€¼ç»™params
            custom_cols=list(set(required_cols)-set(standard_cols))
            class CustomPandasData(bt.feeds.PandasData):
                lines=tuple(custom_cols)
                params={col:-1 for col in custom_cols}#backtraderä¸­çš„lineså’Œparamsæ˜¯ç±»çº§åˆ«çš„å±æ€§ï¼Œä¸éœ€è¦åœ¨åˆ›å»ºå®ä¾‹æ—¶ä¼ é€’;paramsæ—¢å¯ä»¥ç”¨å­—å…¸å½¢å¼å®šä¹‰ï¼Œä¹Ÿå¯ä»¥ç”¨å…ƒç»„å½¢å¼å®šä¹‰ã€‚è¿™ä¸¤ç§æ–¹å¼éƒ½æ˜¯æœ‰æ•ˆçš„
            data_feed=CustomPandasData(dataname=data)
        return data_feed

class AkshareETFLoader(BaseDataLoader):
    def fetch_data(self,**kwargs):
        symbol = kwargs.get('symbol')
        start_date = kwargs.get('start_date')
        end_date = kwargs.get('end_date')
        
        # æ£€æŸ¥å‚æ•°
        if not symbol:
            raise ValueError("fund_codeå‚æ•°ä¸èƒ½ä¸ºç©º")
        
        data = ak.fund_etf_hist_em(symbol=symbol, period="daily", start_date=start_date, end_date=end_date, adjust="hfq")
        
        # ç»Ÿä¸€è½¬æ¢ä¸ºè‹±æ–‡åˆ—å
        column_map = {
            "æ—¥æœŸ": "datetime", 
            "æ”¶ç›˜": "close", 
            "å¼€ç›˜": "open", 
            "æœ€é«˜": "high", 
            "æœ€ä½": "low", 
            "æˆäº¤é‡": "volume",
            "æˆäº¤é¢": "amount",
            "æŒ¯å¹…": "amplitude",
            "æ¶¨è·Œå¹…": "change_pct",
            "æ¶¨è·Œé¢": "change_amount",
            "æ¢æ‰‹ç‡": "turnover_rate"
        }
        
        # é‡å‘½ååˆ—
        data = data.rename(columns=column_map)
        
        # è½¬æ¢æ—¥æœŸå¹¶è®¾ç½®ä¸ºç´¢å¼•
        data['datetime'] = pd.to_datetime(data['datetime'])
        data.set_index('datetime', inplace=True)
        
        print(f"ğŸ“Š æ•°æ®èŒƒå›´: {data.index.min().date()} åˆ° {data.index.max().date()}")
        return data

